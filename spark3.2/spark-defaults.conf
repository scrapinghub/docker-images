# Default system properties included when running spark-submit.
# This is useful for setting default environmental settings.

spark.files                 file:///etc/hadoop/conf/hdfs-site.xml,file:///etc/hadoop/conf/core-site.xml
spark.mesos.coarse          true
spark.cores.max             2
spark.executor.cores        1
spark.executor.memory       1g
spark.mesos.role            spark
spark.mesos.constraints     role:c2-node
spark.mesos.uris            file:///root/.dockercfg

##########################################################################################
# Settings for dynamic resource allocation, DO NOT EDIT IT unless you know what you're doing.
##########################################################################################
spark.dynamicAllocation.enabled                         true
spark.shuffle.service.enabled                           true
# default 0
spark.dynamicAllocation.initialExecutors                2
# default 1min
spark.dynamicAllocation.executorIdleTimeout             10m
# default infinity
spark.dynamicAllocation.cachedExecutorIdleTimeout       1h
# default infinity
spark.dynamicAllocation.maxExecutors                    10
# The executor must share the same data dir with the external shuffle service
# See https://issues.apache.org/jira/browse/SPARK-17555
spark.mesos.executor.docker.volumes                    /tmp/spark:/tmp/spark:rw
spark.local.dir                                        /tmp/spark
